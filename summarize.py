from openai import OpenAI
from config import OPENAI_API_KEY
import re
from datetime import datetime
from email.utils import parsedate_to_datetime

client = OpenAI(api_key=OPENAI_API_KEY)

def _normalize_date(date_str: str) -> str:
    """
    æŠŠå„ç¨®æ—¥æœŸæ ¼å¼çµ±ä¸€æˆ YYYY/MM/DD,ä¸¦ç§»é™¤æ™‚é–“ã€‚
    æ”¯æ´ï¼š
    - 2026-01-03 01:53:26
    - 2026-01-03
    - Fri, 09 Jan 2026 06:06:48 GMT (RSS)
    - 2026/01/03
    """
    s = (date_str or "").strip()

    # 1) å…ˆæŠ“ ISO / slash æ ¼å¼
    m = re.search(r"(\d{4})[-/](\d{2})[-/](\d{2})", s)
    if m:
        return f"{m.group(1)}/{m.group(2)}/{m.group(3)}"

    # 2) RSS / RFC822 ä¾‹ï¼šFri, 09 Jan 2026 06:06:48 GMT
    try:
        dt = parsedate_to_datetime(s)
        return dt.strftime("%Y/%m/%d")
    except Exception:
        pass

    # 3) å…¶ä»–å¸¸è¦‹æ ¼å¼ï¼ˆä¿åº•ï¼‰
    fmts = [
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%dT%H:%M:%S",
        "%a, %d %b %Y %H:%M:%S %Z",
        "%a, %d %b %Y %H:%M:%S %z",
    ]
    for fmt in fmts:
        try:
            dt = datetime.strptime(s, fmt)
            return dt.strftime("%Y/%m/%d")
        except Exception:
            continue

    # 4) ç„¡æ³•è§£æå°±åŸæ¨£å›å‚³ï¼ˆä½†è‡³å°‘ä¸æœƒå™´éŒ¯ï¼‰
    return s

SYSTEM_PROMPT = (
    "ä½ æ˜¯ä¸€ä½ä¸­ç«‹ã€èª å¯¦ã€å°ˆæ¥­çš„å°ç£ä¸­æ–‡è²¡ç¶“åŠ©ç†ã€‚"
    "ä½ çš„ä»»å‹™æ˜¯æ ¹æ“šæœ€æ–°è³‡æ–™æä¾›å®¢è§€åˆ†æï¼Œç„¡è«–ä½¿ç”¨è€…çš„æå•èªæ°£æ˜¯æ­£é¢æˆ–è² é¢ï¼Œéƒ½å¿…é ˆä¾æ“šè³‡æ–™èª å¯¦å›è¦†ã€‚"
    "è‹¥è³‡æ–™é¡¯ç¤ºè¡¨ç¾ä¸ä½³æˆ–ä¸‹è¡Œé¢¨éšªï¼Œå¿…é ˆæ˜ç¢ºæŒ‡å‡ºã€‚"
    "ä¸å¾—å®‰æ’«æˆ–æ¨¡ç³Šå›ç­”ï¼Œä¹Ÿä¸å¾—å¼·è¡Œæ‰¾å‡ºæ¨‚è§€ç†ç”±ã€‚"
    "è«‹ä¿æŒåˆ†æèªæ°£ï¼Œé‡é»åœ¨äº‹å¯¦èˆ‡è³‡æ–™æœ¬èº«ã€‚"
    "æœ€å¾Œä¸€è¡Œä¸€å¾‹é™„ä¸Šã€Œï¼ˆåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°ï¼‰ã€"
)

def summarize_with_gpt(user_query: str, context: str):
    """
    ä½¿ç”¨ GPT å°ä½¿ç”¨è€…å®Œæ•´å•é¡Œé€²è¡Œåˆ†æèˆ‡æ‘˜è¦ï¼Œçµåˆ RAG contextã€‚
    """

    # === è‹¥ RAG å›å‚³æ‰¾ä¸åˆ°å…¬å¸åç¨±çš„è¨Šæ¯ï¼Œç›´æ¥å›è¦†å›ºå®šæ¨¡æ¿ ===
    if context.startswith("æŠ±æ­‰ï¼Œæ‰¾ä¸åˆ°èˆ‡") or "æŸ¥ç„¡å…¬å¸" in context:
        print("[GPT/Skip] ğŸš« è·³é GPT å‘¼å«ï¼ˆå› æœªè¾¨è­˜å‡ºå…¬å¸åç¨±ï¼‰")
        return f"æŠ±æ­‰ï¼Œæ ¹æ“šç›®å‰çš„è³‡æ–™ï¼Œç„¡æ³•æ‰¾åˆ°èˆ‡ã€Œ{user_query}ã€ç›¸é—œçš„å…¬å¸æˆ–å…¶è‚¡åƒ¹è³‡è¨Šã€‚\nè«‹ç¢ºèªå…¬å¸åç¨±æˆ–ä»£è™Ÿæ˜¯å¦æ­£ç¢ºï¼Œä»¥ä¾¿æä¾›æ›´æº–ç¢ºçš„åˆ†æã€‚\n\nï¼ˆåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°ï¼‰"

    prompt = f"""
ä½¿ç”¨è€…çš„åŸå§‹å•é¡Œå¦‚ä¸‹ï¼š
ã€Œ{user_query}ã€

ä»¥ä¸‹æ˜¯ä½ å¯åƒè€ƒçš„æœ€æ–°æª¢ç´¢è³‡æ–™ï¼ˆè‚¡åƒ¹èˆ‡æ–°èï¼‰ï¼š
---
{context}
---

è«‹æ ¹æ“šä½¿ç”¨è€…çš„å•é¡Œæ„åœ–èˆ‡ä¸Šè¿°è³‡æ–™ï¼Œç”Ÿæˆæœ‰æ¢ç†çš„ä¸­æ–‡å›è¦†ã€‚

âœ… è«‹éµå®ˆä»¥ä¸‹åŸå‰‡ï¼ˆéå¸¸é‡è¦ï¼‰ï¼š

ã€ç«‹å ´åˆ¤æ–·è¦å‰‡ï¼ˆå¿…é ˆéµå®ˆï¼‰ã€‘
ä½ åªèƒ½æ ¹æ“šä¸Šæ–¹è³‡æ–™åšç«‹å ´åˆ¤æ–·ï¼Œä¸å¾—åŠ å…¥æœªæä¾›çš„å…·é«”äº‹å¯¦ã€‚

- åå¤šï¼š
  åŒä¸€æ–¹å‘çš„ã€Œæ­£å‘è­‰æ“šã€è‡³å°‘ 2 é»ï¼Œä¸”è‡³å°‘ 1 é»ä¾†è‡ªå…¨æ–‡æ‘˜éŒ„ï¼›
  ä¸¦ä¸”æ²’æœ‰é‡å¤§è² é¢è­‰æ“šèƒ½ç›´æ¥åé§ã€‚
  ä¾‹ï¼šç‡Ÿæ”¶/ç²åˆ©å‰µé«˜ã€è¨‚å–®å±•æœ›ä¸Šä¿®ã€é‡å¤§åˆ©å¤šå…¬å‘Šã€é—œéµç”¢å“é€²å±•ç­‰ï¼ˆéœ€å¼•ç”¨ï¼‰ã€‚

- åç©ºï¼š
  åŒä¸€æ–¹å‘çš„ã€Œè² å‘è­‰æ“šã€è‡³å°‘ 2 é»ï¼Œä¸”è‡³å°‘ 1 é»ä¾†è‡ªå…¨æ–‡æ‘˜éŒ„ï¼›
  ä¸¦ä¸”æ²’æœ‰é‡å¤§æ­£é¢è­‰æ“šèƒ½ç›´æ¥åé§ã€‚
  ä¾‹ï¼šä¸‹ä¿®å±•æœ›ã€éœ€æ±‚è½‰å¼±ã€é‡å¤§è¨´è¨Ÿ/ç›£ç®¡ã€äº‹æ•…/åœå·¥ã€æ˜é¡¯åˆ©ç©ºæ¶ˆæ¯ç­‰ï¼ˆéœ€å¼•ç”¨ï¼‰ã€‚

- ä¸­æ€§ï¼ˆè§€æœ›ï¼‰ï¼š
  åªè¦ç¬¦åˆä»¥ä¸‹ä»»ä¸€æ¢ä»¶ï¼Œå°±é¸ä¸­æ€§ï¼š
  (a) è­‰æ“šä¸è¶³ï¼ˆå¤šç‚ºæ¨™é¡Œç´šï¼Œæˆ–å…¨æ–‡æ‘˜éŒ„=0ï¼‰
  (b) æ­£è² è­‰æ“šåŒæ™‚å­˜åœ¨ä¸”äº’ç›¸ç‰´è§¸ï¼Œç„¡æ³•ç”¨å…¨æ–‡æ‘˜éŒ„æ¾„æ¸…
  (c) ä½¿ç”¨è€…å•é¡Œéœ€è¦é—œéµæ•¸å­—/å®˜æ–¹èªªæ³•ä½† context ç¼ºå¤±
  (d) åªæœ‰å–®ä¸€ä¾†æºæ”¯æŒæ–¹å‘ï¼ˆä¸è¶³ä»¥å½¢æˆè¶¨å‹¢çµè«–ï¼‰


ã€ä¿¡å¿ƒåˆ¤æ–·è¦å‰‡ï¼ˆå¿…é ˆéµå®ˆï¼‰ã€‘
ä½ å¿…é ˆä¾æ“šã€Œè­‰æ“šå¼·åº¦ã€æ±ºå®šä¿¡å¿ƒï¼Œä¸”è¦ä¿å®ˆï¼š

- é«˜ï¼ˆå¾ˆå°‘å‡ºç¾ï¼‰ï¼š
  åŒä¸€çµè«–æ–¹å‘è‡³å°‘æœ‰ 2 å‰‡ç¨ç«‹ä¾†æºæ”¯æŒï¼Œä¸”è‡³å°‘ 2 å‰‡æ˜¯ã€Œå…¨æ–‡æ‘˜éŒ„ã€å¯å¼•ç”¨ï¼›
  æˆ– 1 å‰‡å…¨æ–‡æ‘˜éŒ„ + å¦å¤– 2 å‰‡ä¾†æºæ¸…å–®æ”¯æŒåŒä¸€äº‹ä»¶/æ–¹å‘ã€‚
  ï¼ˆç°¡å–®èªªï¼šæœ‰å¤šä¾†æºä¸”æœ‰å…§æ–‡è­‰æ“šæ‰çµ¦é«˜ï¼‰

- ä¸­ï¼ˆéœ€è¦æ˜ç¢ºå¯é©—è­‰çš„æ”¯æ’ï¼‰ï¼š
  è‡³å°‘æœ‰ 1 å‰‡ã€Œå…¨æ–‡æ‘˜éŒ„ã€å¯å¼•ç”¨ï¼Œä¸”å¦å¤–è‡³å°‘ 1 å‰‡ä¾†æºæ¸…å–®æ”¯æŒåŒä¸€æ–¹å‘ï¼›
  æˆ–é›–ç„¡å…¨æ–‡æ‘˜éŒ„ï¼Œä½†æœ‰ 3 å‰‡ä»¥ä¸Šä¾†æºæ¸…å–®åœ¨åŒä¸€ä¸»é¡Œä¸Šé«˜åº¦ä¸€è‡´ã€‚
  ï¼ˆåªæœ‰æ¨™é¡Œ/æ‘˜è¦ä¸”æ•¸é‡å°‘æ™‚ï¼Œä¸å¯çµ¦ä¸­ï¼‰

- ä½ï¼ˆé è¨­å‚¾å‘ï¼Œå¸¸è¦‹ï¼‰ï¼š
  åªé æ¨™é¡Œ/æ‘˜è¦æ¨è«–ã€ä¸”ä¾†æºæ¸…å–®å°‘æ–¼ 3 å‰‡ï¼›æˆ–å…¨æ–‡æ‘˜éŒ„ç‚º 0
  æˆ–ä¾†æºäº’ç›¸è¡çªä¸”æ²’æœ‰å…¨æ–‡æ‘˜éŒ„æ¾„æ¸…ï¼›
  æˆ–ä½¿ç”¨è€…å•é¡Œéœ€è¦é—œéµæ•¸å­—/å®˜æ–¹èªªæ³•ä½† context ç¼ºå¤±ã€‚
  -> æ­¤æ™‚æ‡‰æ›´å‚¾å‘å›è¦†ã€Œè³‡æ–™ä¸è¶³ï¼Œç„¡æ³•åˆ¤æ–·ã€ã€‚

ã€è³‡æ–™ä¾†æºèˆ‡èª å¯¦æ€§ï¼ˆå¯é©—è­‰ RAG)ã€‘
0 ä½ åªèƒ½ä½¿ç”¨ä¸Šæ–¹ã€Œ---ã€ä¹‹é–“æä¾›çš„è³‡æ–™å›ç­”ï¼ˆè‚¡åƒ¹è³‡è¨Šã€æ–°èä¾†æºæ¸…å–®ã€å…¨æ–‡æ‘˜éŒ„/æ‘˜è¦ï¼‰ã€‚
    - ä½ ä¸å¾—æé€ ä»»ä½•å…·é«”äº‹å¯¦ï¼ˆæ•¸å­—ã€æ—¥æœŸã€äº‹ä»¶ã€å¼•è¿°ï¼‰ã€‚
    - ä½ å¯ä»¥åŠ å…¥ã€Œä¸€èˆ¬æ€§çš„é‡‘èå¸¸è­˜ã€åšé€šç”¨è§£é‡‹æˆ–é¢¨éšªæé†’ï¼Œä½†å¿…é ˆæ¸…æ¥šæ¨™è¨»ç‚ºã€Œä¸€èˆ¬æƒ…æ³ã€ï¼Œä¸å¾—ç•¶ä½œè³‡æ–™å·²è­‰å¯¦çš„äº‹å¯¦ã€‚

1 å°æ–°èçš„åš´è¬¹è¦å‰‡ï¼ˆé—œéµï¼‰
    - è‹¥æŸå‰‡æ–°èåªæœ‰ã€Œæ¨™é¡Œ/æ‘˜è¦ã€ï¼šä½ å¯ä»¥æè¿°ã€Œæ¨™é¡Œæ‰€èªªçš„äº‹ä»¶ã€ï¼Œä½†å°ã€ŒåŸå› /å½±éŸ¿/å¾ŒçºŒã€åªèƒ½åšä¸€èˆ¬æ€§æ¨è«–ï¼Œä¸”ä¸å¾—æŠŠæ¨è«–è¬›æˆå·²ç¢ºå®šäº‹å¯¦ã€‚
    - è‹¥æœ‰ã€Œå…¨æ–‡æ‘˜éŒ„ã€ï¼šä½ å¯ä»¥æ›´æ˜ç¢ºæ•´ç†é‡é»ï¼Œä½†ä»ä¸å¾—è¶…å‡ºæ‘˜éŒ„å…§å®¹ã€‚

ã€å¼•ç”¨è¦å‰‡ï¼ˆå¿…é ˆéµå®ˆï¼‰ã€‘
2 åªè¦å¥å­ä¸­åŒ…å«ï¼š
    - å…·é«”äº‹å¯¦ï¼ˆæ•¸å­—ã€æ—¥æœŸã€äº‹ä»¶ã€å¼•è¿°ï¼‰
    - å°å…¬å¸è¿‘æ³çš„åˆ¤æ–· / åŸå› è§£è®€ / è¶¨å‹¢çµè«–
   å°±å¿…é ˆåœ¨å¥å°¾æ¨™è¨»å¼•ç”¨ç·¨è™Ÿï¼Œä¾‹å¦‚ï¼š[1] æˆ– [2][5]

3 å¼•ç”¨ç·¨è™Ÿåªèƒ½ä½¿ç”¨ context ä¸­å‡ºç¾çš„ [1][2]...[8]ï¼›ä¸å¾—ç·¨é€ ä¸å­˜åœ¨çš„ç·¨è™Ÿã€‚

4 è‹¥è³‡æ–™ä¸è¶³ä»¥æ”¯æ’æŸå€‹ã€Œçµè«–/å› æœã€ï¼Œè«‹ç›´æ¥å¯«ï¼š
   ã€Œè³‡æ–™ä¸è¶³ï¼Œç„¡æ³•åˆ¤æ–·ã€‚ã€ä¸¦èªªæ˜ç¼ºå°‘ä»€éº¼ï¼ˆä¾‹å¦‚ï¼šéœ€è¦å…§æ–‡ã€è²¡å ±æ•¸å­—ã€æ³•èªªå…§å®¹ã€å®˜æ–¹å…¬å‘Šï¼‰ã€‚

ã€è¼¸å‡ºé¢¨æ ¼ï¼ˆè®“å›ç­”æ›´åƒé‡‘èåŠ©ç†ã€ä½†ä»å¯é©—è­‰ï¼‰ã€‘
5 ä¸è¦ä¸€ç›´é‡è¤‡ã€Œä¸ç¢ºå®š/çŸ›ç›¾ã€é€™é¡æé†’ï¼š
   - åªæœ‰åœ¨ã€ŒçœŸçš„ç¼ºè³‡æ–™ã€æˆ–ã€Œå¼•ç”¨ä¾†æºå½¼æ­¤äº’ç›¸æ‰“æ¶ã€æ™‚ï¼Œæ‰å¯«è³‡æ–™ä¸è¶³æˆ–æŒ‡å‡ºè¡çªã€‚
   - å…¶ä»–æƒ…æ³è«‹ç”¨ã€Œç›®å‰è³‡æ–™é¡¯ç¤ºâ€¦ã€â†’ã€Œå› æ­¤â€¦ã€çš„æ”¶æ–‚å¯«æ³•ï¼Œç›´æ¥çµ¦ä½¿ç”¨è€…å¯ç”¨çš„æ•´ç†ã€‚

6 ä¸æä¾›æ˜ç¢ºè²·è³£å»ºè­°ã€ç›®æ¨™åƒ¹æˆ–é€²å‡ºå ´é»ï¼›åƒ…åšè³‡è¨Šæ•´ç†ã€å¯èƒ½åŸå› ï¼ˆå¿…è¦æ™‚æ¨™è¨»ä¸€èˆ¬æƒ…æ³ï¼‰èˆ‡é¢¨éšªæé†’ã€‚

ã€è¼¸å‡ºæ ¼å¼ï¼ˆå›ºå®šï¼‰ã€‘

âœ…ã€ä¸€å¥è©±çµè«–ã€‘ï¼š
- è‹¥èƒ½å½¢æˆåˆ¤æ–·ï¼šç”¨ä¸€å¥è©±å›ç­”ä½¿ç”¨è€…å•é¡Œï¼Œä¸¦çµ¦ã€Œç«‹å ´ï¼šåå¤š/ä¸­æ€§/åç©ºã€+ã€Œä¿¡å¿ƒï¼šé«˜/ä¸­/ä½ã€ã€‚
- è‹¥ç„¡æ³•å½¢æˆåˆ¤æ–·ï¼šè«‹ç›´æ¥å¯«ã€Œè³‡æ–™ä¸è¶³ï¼Œç„¡æ³•åˆ¤æ–·ã€ï¼Œä¸¦èªªæ˜ç¼ºå°‘ä»€éº¼ï¼›æ­¤æ™‚ä¸å¿…ç¡¬çµ¦ç«‹å ´æˆ–å¼•ç”¨ã€‚

ğŸ“ˆã€è‚¡åƒ¹å‹•æ…‹ã€‘ï¼š
- æœ¬æ®µåªä½¿ç”¨ context ä¸­çš„ã€Œ[è‚¡åƒ¹è³‡è¨Š]ã€æ¬„ä½ï¼Œä¸éœ€è¦ä¹Ÿä¸å…è¨±ä½¿ç”¨æ–°èå¼•ç”¨ç·¨è™Ÿ [1]..[8]ã€‚
- è«‹ä¾ [è‚¡åƒ¹è³‡è¨Š] çš„æ•¸å€¼è¼¸å‡º 1 è¡Œï¼Œæ ¼å¼å›ºå®šç‚ºï¼š
  - å…¬å¸åï¼ˆè‚¡ç¥¨ä»£è™Ÿï¼‰ç›®å‰è‚¡åƒ¹ç‚ºç¾åƒ¹å…ƒï¼Œè¼ƒå‰ä¸€æ—¥ä¸Šæ¼²/ä¸‹è·Œæ¼²è·Œå…ƒï¼Œæ¼²å¹…/è·Œå¹…ç‚ºæ¼²è·Œå¹…%ã€‚

ğŸ“Œã€è­‰æ“šé‡é»ã€‘ï¼š
- 3-6 é»æ¢åˆ—ï¼Œæ¯é»ä¸€å¥è©±ï¼Œæ¯é»å¥å°¾å¿…é ˆå¼•ç”¨ï¼Œä¾‹å¦‚ï¼š[1] æˆ– [2][5]

âš ï¸ã€é¢¨éšªèˆ‡éœ€è¦è¿½è¹¤çš„é»ã€‘ï¼š
- 2-4 é»æ¢åˆ—ï¼ˆä¾‹å¦‚ï¼šç¼ºå°‘å…§æ–‡/ç¼ºå°‘æ•¸å­—/äº‹ä»¶å°šæœªç¢ºèª/åˆ©å¤šåˆ©ç©ºçš„æ¢ä»¶ï¼‰ã€‚
  èƒ½å¼•ç”¨å°±å¼•ç”¨ï¼›ä¸èƒ½å¼•ç”¨å°±ç›´æ¥èªªè³‡æ–™ä¸è¶³ã€‚



"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": prompt},
            ],
            temperature=0.4,  # é™ä½æº«åº¦ï¼Œè®“èªæ°£æ›´ç©©é‡ã€å°‘å®‰æ’«èª
            max_tokens=1000,
        )

        # âœ… æ–°å¢é€™æ®µä¾†é¡¯ç¤º Token ç”¨é‡
        usage = resp.usage
        print(f"LOG: Token ä½¿ç”¨æƒ…æ³ -> prompt={usage.prompt_tokens}, completion={usage.completion_tokens}, total={usage.total_tokens}")
        cost_usd = usage.prompt_tokens * 0.00015 / 1000 + usage.completion_tokens * 0.0006 / 1000
        cost_twd = cost_usd * 32
        print(f"LOG: é ä¼°æˆæœ¬ â‰ˆ {cost_twd:.4f} å…ƒå°å¹£\n")


        def _extract_sources_map(context: str) -> dict:
            """
            å¾ context ä¸­æŠ“å‡ºæ–°èä¾†æºæ¸…å–®çš„æ¯ä¸€è¡Œï¼š
            [1] æ¨™é¡Œ | ä¾†æº | æ—¥æœŸ | url
            å›å‚³ dict: { "1": "æ¨™é¡Œ | ä¾†æº | æ—¥æœŸ", ... }  (ä¸å« url)
            """
            src_map = {}
            # æ‰¾æ‰€æœ‰å½¢å¦‚ï¼š[n] ... çš„è¡Œ
            for m in re.finditer(r"^\[(\d+)\]\s*(.+)$", context, flags=re.MULTILINE):
                idx = m.group(1)
                line = m.group(2).strip()

                # ä½ çš„ä¾†æºè¡Œæ˜¯ï¼šæ¨™é¡Œ | source | date 
                parts = [p.strip() for p in line.split("|")]
                if len(parts) >= 4:
                    title = parts[0]
                    source = parts[1]
                    date_raw = parts[2]

                    # (å¯é¸) å»æ‰ title å°¾å·´é‡è¤‡çš„ã€Œ- ä¾†æºã€
                    if " - " in title:
                        tail = title.rsplit(" - ", 1)[-1].strip()
                        if tail == source:
                            title = title.rsplit(" - ", 1)[0].strip()

                    date_norm = _normalize_date(date_raw)

                    # æœ€çµ‚åªè¼¸å‡ºï¼šæ¨™é¡Œ | ä¾†æº | YYYY/MM/DD
                    src_map[idx] = f"{title} | {source} | {date_norm}"
                else:
                    continue  # ä¸æ˜¯ä¾†æºè¡Œå°±è·³é


            return src_map


        def _extract_used_citations(text: str) -> list:
            """
            å¾æ¨¡å‹è¼¸å‡ºæŠ“å‡ºæ‰€æœ‰å¼•ç”¨ç·¨è™Ÿ [n]
            å›å‚³å»é‡å¾Œã€ä¾æ•¸å­—æ’åºçš„ list[str]
            """
            ids = re.findall(r"\[(\d+)\]", text)
            ids = sorted(set(ids), key=lambda x: int(x))
            return ids


        def _remove_existing_reference_block(text: str) -> str:
            """
            ç§»é™¤æ¨¡å‹è‡ªå·±ç”¢ç”Ÿçš„ ğŸ”—ã€å¼•ç”¨ä¾†æºã€‘æ®µè½ï¼ˆé¿å…é‡è¤‡/æ¼åˆ—ï¼‰
            """
            # å¾ ğŸ”—ã€å¼•ç”¨ä¾†æºã€‘ é–‹å§‹åˆªåˆ°æ–‡æœ«ï¼ˆæˆ–ä¸‹ä¸€å€‹æ®µè½ï¼‰ï¼Œé€™è£¡ç°¡å–®åˆªåˆ°æ–‡æœ«æœ€ç©©
            return re.sub(r"\n*ğŸ”—ã€å¼•ç”¨ä¾†æºã€‘[\s\S]*$", "", text).rstrip()


        # ---- after receiving model output ----
        text = resp.choices[0].message.content.strip()

        # 1) æŠ“å‡ºæ­£æ–‡ç”¨åˆ°çš„å¼•ç”¨ç·¨è™Ÿ
        used_ids = _extract_used_citations(text)

        # 2) å¾ context æŠ“å‡ºæ¯å€‹ç·¨è™Ÿå°æ‡‰çš„ä¾†æºè¡Œï¼ˆä¸å« urlï¼‰
        src_map = _extract_sources_map(context)

        # 3) çµ„è£å¼•ç”¨ä¾†æºæ®µè½ï¼ˆåªåˆ—å¯¦éš›ç”¨åˆ°çš„ï¼‰
        lines = []
        for cid in used_ids:
            if cid in src_map:
                lines.append(f"- [{cid}] {src_map[cid]}")
            else:
                # è‹¥æ¨¡å‹å¼•ç”¨åˆ° context æ²’æœ‰çš„ç·¨è™Ÿï¼Œé€™è£¡é¸æ“‡ä¸åˆ—å‡ºä¸¦å° logï¼ˆä¹Ÿå¯ç›´æ¥å¿½ç•¥ï¼‰
                print(f"[WARN] citation [{cid}] not found in context source list")

        ref_block = "ğŸ”—ã€å¼•ç”¨ä¾†æºã€‘ï¼š\n" + ("\n".join(lines) if lines else "-ï¼ˆæœ¬æ¬¡æœªä½¿ç”¨æ–°èå¼•ç”¨ï¼‰")

        # 4) ç§»é™¤æ¨¡å‹åŸæœ¬å¼•ç”¨ä¾†æºæ®µè½ï¼Œæ›æˆä½ ç¨‹å¼ç”Ÿæˆçš„
        text = _remove_existing_reference_block(text)
        text = text.rstrip() + "\n\n" + ref_block

        # 5) å…è²¬ä¿åº•ï¼ˆé¿å…æ¼æ‰æˆ–é‡è¤‡ï¼‰
        disclaimer = "ï¼ˆåƒ…ä¾›åƒè€ƒï¼Œä¸æ§‹æˆæŠ•è³‡å»ºè­°ï¼‰"
        text = text.replace(disclaimer + "\n" + disclaimer, disclaimer)
        if not text.endswith(disclaimer):
            text = text.rstrip() + "\n\n" + disclaimer

        return text

    except Exception as e:
        print(f"LOG: OpenAI API å‘¼å«å¤±æ•—: {e}")
        return "æŠ±æ­‰ï¼ŒAI åˆ†ææ™‚ç™¼ç”Ÿå•é¡Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
